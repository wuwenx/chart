const { ChatOpenAI } = require('@langchain/openai')
const { ChatGoogleGenerativeAI } = require('@langchain/google-genai')
const { OpenAIEmbeddings } = require('@langchain/openai')

class AIModelManager {
  constructor() {
    this.provider = process.env.AI_MODEL_PROVIDER || 'gemini'
    this.llm = null
    this.embeddings = null
    this.initializeModels()
  }

  initializeModels() {
    try {
      switch (this.provider.toLowerCase()) {
        case 'openai':
          this.initializeOpenAI()
          break
        case 'gemini':
          this.initializeGemini()
          break
        default:
          console.log('âš ï¸ æœªè¯†åˆ«çš„æ¨¡å‹æä¾›å•†ï¼Œé»˜è®¤ä½¿ç”¨ Gemini')
          this.initializeGemini()
      }
      console.log(`âœ… AI æ¨¡å‹åˆå§‹åŒ–å®Œæˆ: ${this.provider}`)
    } catch (error) {
      console.error('âŒ AI æ¨¡å‹åˆå§‹åŒ–å¤±è´¥:', error.message)
      throw error
    }
  }

  initializeOpenAI() {
    if (!process.env.OPENAI_API_KEY) {
      throw new Error('OpenAI API Key æœªé…ç½®')
    }

    this.llm = new ChatOpenAI({
      openAIApiKey: process.env.OPENAI_API_KEY,
      modelName: 'gpt-3.5-turbo',
      temperature: 0.7,
      maxTokens: 1000
    })

    this.embeddings = new OpenAIEmbeddings({
      openAIApiKey: process.env.OPENAI_API_KEY,
      modelName: 'text-embedding-ada-002'
    })
  }

  initializeGemini() {
    if (!process.env.GOOGLE_API_KEY) {
      throw new Error('Google API Key æœªé…ç½®')
    }

    this.llm = new ChatGoogleGenerativeAI({
      apiKey: process.env.GOOGLE_API_KEY,
      modelName: 'gemini-2.0-flash-001',
      temperature: 0.7,
      maxOutputTokens: 1000
    })

    // Gemini ä½¿ç”¨ OpenAI çš„åµŒå…¥æ¨¡å‹ï¼ˆå› ä¸º Gemini æ²¡æœ‰ä¸“é—¨çš„åµŒå…¥æ¨¡å‹ï¼‰
    // æˆ–è€…æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€ä¸ªç®€å•çš„æ–‡æœ¬åµŒå…¥æ›¿ä»£æ–¹æ¡ˆ
    this.embeddings = new SimpleTextEmbeddings()
  }

  getLLM() {
    if (!this.llm) {
      throw new Error('LLM æ¨¡å‹æœªåˆå§‹åŒ–')
    }
    return this.llm
  }

  getEmbeddings() {
    if (!this.embeddings) {
      throw new Error('åµŒå…¥æ¨¡å‹æœªåˆå§‹åŒ–')
    }
    return this.embeddings
  }

  getProvider() {
    return this.provider
  }

  // è·å–æ¨¡å‹ä¿¡æ¯
  getModelInfo() {
    return {
      provider: this.provider,
      llmModel: this.provider === 'openai' ? 'gpt-3.5-turbo' : 'gemini-2.0-flash-001',
      embeddingsModel: this.provider === 'openai' ? 'text-embedding-ada-002' : 'simple-text',
      status: this.llm ? 'ready' : 'not_initialized'
    }
  }
}

// ç®€å•çš„æ–‡æœ¬åµŒå…¥å®ç°ï¼ˆç”¨äº Geminiï¼‰
class SimpleTextEmbeddings {
  constructor() {
    console.log('ğŸ“ ä½¿ç”¨ç®€å•æ–‡æœ¬åµŒå…¥æ¨¡å‹ï¼ˆé€‚ç”¨äº Geminiï¼‰')
  }

  async embedDocuments(texts) {
    // ç®€å•çš„æ–‡æœ¬å‘é‡åŒ–å®ç°
    // åœ¨å®é™…åº”ç”¨ä¸­ï¼Œæ‚¨å¯èƒ½éœ€è¦ä½¿ç”¨æ›´å¤æ‚çš„åµŒå…¥æ–¹æ³•
    return texts.map(text => this.textToVector(text))
  }

  async embedQuery(text) {
    return this.textToVector(text)
  }

  textToVector(text) {
    // ç®€å•çš„æ–‡æœ¬å‘é‡åŒ–ï¼šåŸºäºå­—ç¬¦é¢‘ç‡
    const vector = new Array(384).fill(0) // 384 ç»´å‘é‡
    const normalizedText = text.toLowerCase().replace(/[^a-z0-9\s]/g, '')
    
    for (let i = 0; i < normalizedText.length; i++) {
      const charCode = normalizedText.charCodeAt(i)
      const index = charCode % 384
      vector[index] += 1
    }
    
    // å½’ä¸€åŒ–å‘é‡
    const magnitude = Math.sqrt(vector.reduce((sum, val) => sum + val * val, 0))
    return vector.map(val => magnitude > 0 ? val / magnitude : 0)
  }
}

module.exports = { AIModelManager }
